- Class: meta
  Course: Topics in Generalized Linear Models
  Lesson: Time for a Change Election Model
  Author: Swirl coders
  Type: Standard
  Organization: Swirl Coders
  Version: 2.2.18

- Class: figure
  Output: "In US presidential elections voters choose electors and electors
  choose the winner. In practice, electors are committed to candidates, but 
  because electors are not strictly proportional to population, the winner of 
  the popular vote may not win the election. This happened most recently in 
  the 2000 election when Al Gore won the popular vote and George W. Bush won 
  the Presidency."
  Figure: bryan.R
  FigureType: new

- Class: text
  Output: "Interest in the outcome of a presidential election begins long 
  before the vote. Polls are taken and pundits speculate. Statisticians had 
  always been in the background, but in 2008 statistics came to the fore with 
  Nate Silver and his website fivethirtyeight.com, (so named because there are 
  538 electors.) In 2012, statistician Drew Linzer forecast election results 
  precisely, using publically available data, R, and a model which he explains 
  on his website votamatic.org (votamatic.org/how-it-works)."

- Class: figure
  Output: "Drew Linzer's algorithm begins, about six months before the vote, 
  with the Time-for-Change (TFC) model proposed by Alan Abromowitz. 
  As the election approaches, Linzer weights polls more heavily and the 
  TFC model less. However, we'll consider only the TFC model here. 
  In its simplest form, it is a linear regression predicting the incumbent party's 
  share of the popular vote in terms of an intercept, the incumbent president's 
  net approval rating in June, the rate of economic growth in the second quarter, 
  and a dummy variable which is 1 if the incumbent party has held the Presidency for 
  two or more terms. As the figure shows, the dummy variable has a large, 
  negative coefficient, hence the model's name."
  Figure: tfc_model.R
  FigureType: new

- Class: figure
  Output: "The TFC model does fit the available data fairly well, as this figure shows. 
  The available data, however, cover only the 17 elections since both presidential 
  approval ratings and quarterly economic performance data have been available."
  Figure: tfc_fit.R
  FigureType: new

- Class: cmd_question
  Output: "Data for the TFC model was loaded into your workspace at the beginning
  of this lesson. It is in a data frame named tfc. In addition to the variables 
  mentioned above, it contains the year, an indicator of whether the incumbent 
  party's candidate won, and the name of the winning candidate. Inspect the data 
  now by typing tfc, head(tfc), or View(tfc)."
  CorrectAnswer: tfc
  AnswerTests: any_of_exprs("tfc", "head(tfc)", "View(tfc)")
  Hint: Enter tfc, head(tfc), or View(tfc).

- Class: text
  Output: "How trustworthy is a 4 parameter model based on 17 observations? 
  Perhaps it is overfitted. Perhaps other plausible models would do just as well. 
  Our objective in this lesson is to compare the TFC model with two generalized 
  linear alternatives."

- Class: cmd_question
  Output: "To begin, derive the TFC model itself by applying R's lm function 
  the tfc data to predict pv in terms of an intercept, approval, q2, and the 
  tfc dummy variable. Store the model in a variable called fit_tfc."
  CorrectAnswer: fit_tfc <- lm(pv ~ approval + q2 + tfc, tfc)
  AnswerTests: creates_lm_model('fit_tfc <- lm(pv ~ approval + q2 + tfc, tfc)')
  Hint: "Enter fit_tfc <- lm(pv ~ approval + q2 + tfc, tfc) or an equivalent
  expression"

- Class: cmd_question
  Output: "Inspect the model using summary(fit_tfc)."
  CorrectAnswer: summary(fit_tfc)
  AnswerTests: omnitest(correctExpr='summary(fit_tfc)')
  Hint: "Enter summary(fit_tfc)."

- Class: mult_question
  Output: 'According to the summary, all four coefficients are significantly 
  different from zero. The term, "significantly," suggests there some uncertainty
  about their values. Where does this presumed uncertainty originate?'
  AnswerChoices: With the data.;With numerical precision.;With the TFC model.
  CorrectAnswer: With the data.
  AnswerTests: omnitest(correctVal= 'With the data.')
  Hint: "The model is well defined and numerical precision is pretty good these days."

- Class: mult_question
  Output: "The data is presumed to be generated by a process which involves 
  randomness. In that sense the data is a random variable, (or a sequence of 
  random variables if you prefer.) The coefficients of fit_tfc are the result 
  of a deterministic procedure, linear regression, applied to a random variable. 
  Does this mean the coefficients themselves are random variables?"
  AnswerChoices: Yes.;Not necessarily.;No.
  CorrectAnswer: Yes.
  AnswerTests: omnitest(correctVal= 'Yes.')
  Hint: "A sample mean is also the result of a deterministic procedure, taking an
  average, applied to data. If the data varies randomly, so will its average."

- Class: mult_question
  Output: "The result of applying a deterministic procedure to a random variable 
  is often called a statistic. Assumptions about a statistic's distribution will 
  depend on assumptions about the data from which the statistic is derived. 
  What embodies those assumptions?"
  AnswerChoices: The model.;The Central Limit Theorem.;The data.;Linear regression. 
  CorrectAnswer: The model.
  AnswerTests: omnitest(correctVal= 'The model.')
  Hint: "Generally the process which generates the data is not fully known.
  Hence, guesses or assumptions about that process must be made. These guesses
  or assumptions are formalized as a model."

- Class: cmd_question
  Output: "The assumptions embodied in the TFC model are that the continuous 
  variables, pv, approval, and q2, are jointly normally distributed with means 
  depending on the dummy variable, tfc. The parameters derived by linear regression
  maximize the likelihood of the observed data, given those assumptions. The R 
  function, logLik, calculates the natural logarithm of this likelihood. 
  Enter logLik(fit_tfc) to calculate it now."
  CorrectAnswer: logLik(fit_tfc)
  AnswerTests: omnitest(correctExpr='logLik(fit_tfc)')
  Hint: "Enter logLik(fit_tfc)."

- Class: cmd_question
  Output: "If the coefficients are statistics, so are other parameters of fit_tfc, 
  such as standard errors. The significance of a coefficient is based on its 
  distance from zero, measured in multiples of standard errors. Thus, a 
  coefficient's significance is also based on the assumption that the data is 
  generated in the way the model assumes. A different model, hence different 
  assumptions, can change that. To illustrate, create a model called fit_win 
  which predicts win in terms of an intercept, approval, q2, and tfc. Use glm with 
  family=binomial."
  CorrectAnswer: fit_win <- glm(win ~ approval + q2 + tfc, tfc, family=binomial)
  AnswerTests: creates_glm_model('fit_win <- glm(win ~ approval + q2 + tfc, tfc, family=binomial)')
  Hint: "Enter fit_win <- glm(win ~ approval + q2 + tfc, tfc, family=binomial), or
  an equivalent expression."

- Class: cmd_question
  Output: "In this case, glm maximizes the likelihood of observing the data, 
  assuming that approval, q2, and the log odds of a win are jointly normally 
  distributed with means depending on the dummy variable. Note that these log 
  odds are latent (not observed) but determine the probability of a win in any 
  given election. Use summary(fit_win) to examine the parameters of this 
  maximum likelihood model."
  CorrectAnswer: summary(fit_win)
  AnswerTests: omnitest(correctExpr='summary(fit_win)')
  Hint: Enter summary(fit_win).

- Class: cmd_question
  Output: "In this case, none of the coefficients are significant; all are well
  within two standard errors of zero. But if the coefficients were all zero, an 
  hypothesis which we can't reject, then wins would not depend on the predictors 
  at all. Use logLik to find the log likelihood of the data given this model."
  CorrectAnswer: logLik(fit_win)
  AnswerTests: omnitest(correctExpr='logLik(fit_win)')
  Hint: Enter logLik(fit_win).

- Class: text
  Output: "The data is more likely under this model than under the original 
  tfc model, (since -4.1 is bigger than -32.9,) despite the possible 
  insignificance of its coefficients. Of course the likelihoods themselves 
  are statistics. They, too, depend on the data and the assumptions implicit 
  in the model. In effect, they are probabilities conditional on model 
  assumptions and parameter estimates."

- Class: text
  Output: "Although it is natural to use the binary win/loss outcome with a 
  binomial glm model, it is not the same thing as using percent of the popular 
  vote, pv. In that sense, fit_tfc and fit_win are not models of precisely the 
  same data. However, we could have used probabilities rather than binary 
  outcomes in the model. To do so we would merely divide pv by 100 to convert 
  from percent to fraction of popular vote, hence be using essentially 
  the same data as for fit_tfc."

- Class: cmd_question
  Output: "Create a model named fit_pv using 
  glm(pv/100 ~ approval + q2 + tfc, tfc, family=binomial). 
  The command will result in a warning that non-integer, not binary, 
  outcomes are being used. Since we have used probabilities on purpose, 
  the warning may be safely ignored. Don't forget to divide pv by 100."
  CorrectAnswer: fit_pv <- glm(pv/100 ~ approval + q2 + tfc, tfc, family=binomial)
  AnswerTests: creates_glm_model('fit_pv <- glm(pv/100 ~ approval + q2 + tfc, tfc, family=binomial)')
  Hint: "Enter fit_pv <- glm(pv/100 ~ approval + q2 + tfc, tfc, family=binomial)
  or an equivalent expression."

- Class: figure
  Output: "In this case the continuous predictors and the log odds, log(p/(1-p)), 
  of the given probabilities, p = pv/100, are assumed to be jointly normally 
  distributed with means depending on the dummy variable, tfc. In effect, 
  p represents the probability that a random voter will vote for the candidate 
  of the incumbent party. As can be seen in the figure, appears to fit the data 
  as well as the original TFC model."
  Figure: pv_glm_model.R
  FigureType: new

- Class: cmd_question
  Output: "Use logLik to calculate the data's likelihood given this model."
  CorrectAnswer: logLik(fit_pv)
  AnswerTests: omnitest(correctExpr='logLik(fit_pv)')
  Hint: Enter logLik(fit_pv).

- Class: cmd_question
  Output: "Again, the likelihood of the data is greater for this model than
  for the original TFC. Use summary(fit_pv) to check the significance of
  its regressor's coefficients."
  CorrectAnswer: summary(fit_pv)
  AnswerTests: omnitest(correctExpr='summary(fit_pv)')
  Hint: Enter summary(fit_pv).

- Class: mult_question
  Output: "We have an original model for which the regressors--approval, q2, and tfc--
  are deemed very significant, and two glm models for which the regressors' significance is
  dubious. However, for the two glm models the likelihood of the observed data is greater 
  than for the original. What might be a reasonable interpretation of this state of affairs?"
  AnswerChoices: "It casts some doubt on the TFC model;Interpretation depends on the relative plausibility of the three models;There is insufficient data for interpretation;Any and all of these choices are reasonable."
  CorrectAnswer: "Any and all of these choices are reasonable."
  AnswerTests: omnitest()
  Hint: "Any and all of these choices are reasonable."

- Class: text
  Output: "Any and all of these choices are reasonable. The real point of this lesson is that a model embodies
  assumptions about a process which might have generated the data. All of the models considered here limit
  attention to three regressors, ignoring the possibility that the Vietnam War may have been important to
  the election of 1968 for instance."
